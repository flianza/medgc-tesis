{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "065352f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-26 16:25:40,611 - kedro.framework.session.store - INFO - `read()` not implemented for `BaseSessionStore`. Assuming empty store.\n",
      "2022-03-26 16:25:41,521 - root - INFO - ** Kedro project MEDGC Tesis\n",
      "2022-03-26 16:25:41,522 - root - INFO - Defined global variable `context`, `session`, `catalog` and `pipelines`\n"
     ]
    }
   ],
   "source": [
    "%load_ext kedro.extras.extensions.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5513da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\modules\\grl.py:57: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\modules\\grl.py:57: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\adaptation\\cdan.py:137: DeprecationWarning: invalid escape sequence \\o\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\adaptation\\cdan.py:137: DeprecationWarning: invalid escape sequence \\o\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\adaptation\\mdd.py:268: DeprecationWarning: invalid escape sequence \\l\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\adaptation\\mdd.py:268: DeprecationWarning: invalid escape sequence \\l\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\adaptation\\pada.py:149: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\adaptation\\pada.py:149: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\common\\utils\\analysis\\__init__.py:20: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\common\\utils\\analysis\\__init__.py:20: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\common\\utils\\analysis\\a_distance.py:44: DeprecationWarning: invalid escape sequence \\m\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\common\\utils\\analysis\\a_distance.py:44: DeprecationWarning: invalid escape sequence \\m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "sys.path.append('../../..')\n",
    "from dalib.modules.domain_discriminator import DomainDiscriminator\n",
    "from dalib.adaptation.dann import DomainAdversarialLoss, ImageClassifier\n",
    "from common.utils.data import ForeverDataIterator\n",
    "from common.utils.metric import accuracy, ConfusionMatrix\n",
    "from common.utils.meter import AverageMeter, ProgressMeter\n",
    "from common.utils.logger import CompleteLogger\n",
    "from common.utils.analysis import collect_feature, tsne, a_distance\n",
    "\n",
    "import common.vision.datasets as datasets\n",
    "from common.vision.transforms import ResizeImage\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "import types\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecd0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional, Tuple, Any\n",
    "from common.vision.datasets.imagelist import ImageList\n",
    "\n",
    "class TDS(ImageList):\n",
    "    image_list = {\n",
    "        \"train\": \"image_list/tds_train.txt\",\n",
    "        \"test\": \"image_list/tds_test.txt\",\n",
    "        \"val\": \"image_list/tds_val.txt\"\n",
    "    }\n",
    "    CLASSES = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    def __init__(self, root, mode=\"L\", split='train', download: Optional[bool] = True, **kwargs):\n",
    "        assert split in ['train', 'test', 'val']\n",
    "        data_list_file = os.path.join(root, self.image_list[split])\n",
    "\n",
    "        assert mode in ['L', 'RGB']\n",
    "        self.mode = mode\n",
    "        super(TDS, self).__init__(root, TDS.CLASSES, data_list_file=data_list_file, **kwargs)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, int]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        return (tuple): (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.samples[index]\n",
    "        img = self.loader(path).convert(self.mode)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None and target is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return img, target\n",
    "\n",
    "    @classmethod\n",
    "    def get_classes(self):\n",
    "        return TDS.CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb3a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e0ad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0145f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_source_iter: ForeverDataIterator, train_target_iter: ForeverDataIterator,\n",
    "          model: ImageClassifier, domain_adv: DomainAdversarialLoss, optimizer: SGD,\n",
    "          lr_scheduler: LambdaLR, epoch: int, args: argparse.Namespace):\n",
    "          \n",
    "    batch_time = AverageMeter('Time', ':5.2f')\n",
    "    data_time = AverageMeter('Data', ':5.2f')\n",
    "    losses = AverageMeter('Loss', ':6.2f')\n",
    "    cls_accs = AverageMeter('Cls Acc', ':3.1f')\n",
    "    domain_accs = AverageMeter('Domain Acc', ':3.1f')\n",
    "    progress = ProgressMeter(args.iters_per_epoch,\n",
    "                            [batch_time, data_time, losses, cls_accs, domain_accs],\n",
    "                            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    domain_adv.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i in range(args.iters_per_epoch):\n",
    "        x_s, labels_s = next(train_source_iter)\n",
    "        x_t, _ = next(train_target_iter)\n",
    "\n",
    "        x_s = x_s.to(device)\n",
    "        x_t = x_t.to(device)\n",
    "        labels_s = labels_s.to(device)\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # compute output\n",
    "        x = torch.cat((x_s, x_t), dim=0)\n",
    "        y, f = model(x)\n",
    "        y_s, y_t = y.chunk(2, dim=0)\n",
    "        f_s, f_t = f.chunk(2, dim=0)\n",
    "\n",
    "        cls_loss = F.cross_entropy(y_s, labels_s)\n",
    "        transfer_loss = domain_adv(f_s, f_t)\n",
    "        domain_acc = domain_adv.domain_discriminator_accuracy\n",
    "        loss = cls_loss + transfer_loss * args.trade_off\n",
    "\n",
    "        cls_acc = accuracy(y_s, labels_s)[0]\n",
    "\n",
    "        losses.update(loss.item(), x_s.size(0))\n",
    "        cls_accs.update(cls_acc.item(), x_s.size(0))\n",
    "        domain_accs.update(domain_acc.item(), x_s.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f83a9511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(random_horizontal_flip=True, random_color_jitter=False,\n",
    "                        resize_size=224, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225)):\n",
    "    \"\"\"\n",
    "    resizing mode:\n",
    "        - default: resize the image to 256 and take a random resized crop of size 224;\n",
    "        - cen.crop: resize the image to 256 and take the center crop of size 224;\n",
    "        - res: resize the image to 224;\n",
    "    \"\"\"\n",
    "    transforms = [ResizeImage(resize_size)]\n",
    "    \n",
    "    if random_horizontal_flip:\n",
    "        transforms.append(T.RandomHorizontalFlip())\n",
    "    if random_color_jitter:\n",
    "        transforms.append(T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5))\n",
    "        \n",
    "    transforms.extend([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=norm_mean, std=norm_std)\n",
    "    ])\n",
    "    \n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def get_val_transform(resize_size=224, norm_mean=(0.485, 0.456, 0.406), norm_std=(0.229, 0.224, 0.225)):\n",
    "    \"\"\"\n",
    "    resizing mode:\n",
    "        - default: resize the image to 256 and take the center crop of size 224;\n",
    "        - res.: resize the image to 224\n",
    "    \"\"\"\n",
    "    return T.Compose([\n",
    "        ResizeImage(resize_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=norm_mean, std=norm_std)\n",
    "    ])\n",
    "\n",
    "def get_dataset(dataset_name, root, train_source_transform, val_transform, train_target_transform=None):\n",
    "    if train_target_transform is None:\n",
    "        train_target_transform = train_source_transform\n",
    "        \n",
    "    train_source_dataset = datasets.MNIST(osp.join(root, 'MNIST'), download=True, transform=train_source_transform)\n",
    "    train_target_dataset = TDS(osp.join(root, 'TDS'), split='train', download=True, transform=val_transform)\n",
    "    val_dataset = TDS(osp.join(root, 'TDS'), split='val', download=True, transform=val_transform)\n",
    "    test_dataset = TDS(osp.join(root, 'TDS'), split='test', download=True, transform=val_transform)\n",
    "    class_names = datasets.MNIST.get_classes()\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    return train_source_dataset, train_target_dataset, val_dataset, test_dataset, num_classes, class_names\n",
    "\n",
    "def get_model():\n",
    "    import torch.nn as nn\n",
    "\n",
    "    class LeNet(nn.Sequential):\n",
    "        def __init__(self, num_classes=10):\n",
    "            super(LeNet, self).__init__(\n",
    "                nn.Conv2d(1, 20, kernel_size=5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(20, 50, kernel_size=5),\n",
    "                nn.Dropout2d(p=0.5),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(start_dim=1),\n",
    "                nn.Linear(50 * 4 * 4, 500),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.5),\n",
    "            )\n",
    "            self.num_classes = num_classes\n",
    "            self.out_features = 500\n",
    "\n",
    "        def copy_head(self):\n",
    "            return nn.Linear(500, self.num_classes)\n",
    "    \n",
    "    return LeNet()\n",
    "\n",
    "def validate(val_loader, model, args, device) -> float:\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    if args.per_class_eval:\n",
    "        confmat = ConfusionMatrix(len(args.class_names))\n",
    "    else:\n",
    "        confmat = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, = accuracy(output, target, topk=(1,))\n",
    "            if confmat:\n",
    "                confmat.update(target, output.argmax(1))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1.item(), images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f}'.format(top1=top1))\n",
    "        if confmat:\n",
    "            print(confmat.format(args.class_names))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36cc2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = types.SimpleNamespace()\n",
    "args.log = 'dann'\n",
    "args.phase = 'analysis'\n",
    "args.no_hflip = True\n",
    "args.resize_size = 28\n",
    "args.norm_mean = 0.5\n",
    "args.norm_std = 0.5\n",
    "args.class_names = None\n",
    "args.data = \"as\"\n",
    "args.root = \"\"\n",
    "args.batch_size = 32\n",
    "args.workers = 0\n",
    "args.no_pool = True\n",
    "args.bottleneck_dim = 256\n",
    "args.lr = 0.01\n",
    "args.lr_gamma = 0.001\n",
    "args.lr_decay = 0.75\n",
    "args.momentum = 0.9\n",
    "args.weight_decay = 1e-3\n",
    "args.epochs = 5\n",
    "args.iters_per_epoch = 2500\n",
    "args.trade_off = 1.\n",
    "args.print_freq = 100\n",
    "args.per_class_eval = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c44b171",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logger = CompleteLogger(args.log, args.phase)\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282dbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "train_transform = get_train_transform(resize_size=args.resize_size, norm_mean=args.norm_mean, norm_std=args.norm_std)\n",
    "val_transform = get_val_transform(resize_size=args.resize_size, norm_mean=args.norm_mean, norm_std=args.norm_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4987e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image_list\n",
      "Downloading https://cloud.tsinghua.edu.cn/seafhttp/files/983f17fd-82d5-4919-8817-317c4f14547f/image_list.zip to MNIST\\image_list.zip\n",
      "233472it [00:02, 87705.53it/s]                             \n",
      "Extracting MNIST\\image_list.zip to MNIST\n",
      "Downloading mnist_train_image\n",
      "Downloading https://cloud.tsinghua.edu.cn/seafhttp/files/981517c8-807e-420a-9891-030fab5c1ab6/mnist_image.tar.gz to MNIST\\mnist_image.tar.gz\n",
      "34944000it [05:35, 104145.41it/s]                              \n",
      "Extracting MNIST\\mnist_image.tar.gz to MNIST\n",
      "lr: 0.001\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\dalib-0.1-py3.7.egg\\dalib\\modules\\grl.py:71: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "Epoch: [0][   0/2500]\tTime  4.32 ( 4.32)\tData  0.83 ( 0.83)\tLoss   3.14 (  3.14)\tCls Acc 6.2 (6.2)\tDomain Acc 42.2 (42.2)\n",
      "Epoch: [0][ 100/2500]\tTime  0.04 ( 0.09)\tData  0.03 ( 0.05)\tLoss   1.32 (  2.17)\tCls Acc 71.9 (42.0)\tDomain Acc 79.7 (72.8)\n",
      "Epoch: [0][ 200/2500]\tTime  0.05 ( 0.07)\tData  0.04 ( 0.04)\tLoss   1.22 (  1.78)\tCls Acc 81.2 (55.1)\tDomain Acc 75.0 (75.0)\n",
      "Epoch: [0][ 300/2500]\tTime  0.04 ( 0.06)\tData  0.03 ( 0.04)\tLoss   1.00 (  1.59)\tCls Acc 81.2 (61.4)\tDomain Acc 82.8 (75.9)\n",
      "Epoch: [0][ 400/2500]\tTime  0.05 ( 0.06)\tData  0.03 ( 0.04)\tLoss   1.07 (  1.47)\tCls Acc 65.6 (65.2)\tDomain Acc 85.9 (76.4)\n",
      "Epoch: [0][ 500/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.12 (  1.40)\tCls Acc 75.0 (67.9)\tDomain Acc 79.7 (76.7)\n",
      "Epoch: [0][ 600/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.07 (  1.34)\tCls Acc 87.5 (70.0)\tDomain Acc 68.8 (76.8)\n",
      "Epoch: [0][ 700/2500]\tTime  0.04 ( 0.05)\tData  0.04 ( 0.04)\tLoss   0.92 (  1.29)\tCls Acc 78.1 (71.6)\tDomain Acc 82.8 (76.9)\n",
      "Epoch: [0][ 800/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.68 (  1.26)\tCls Acc 96.9 (73.1)\tDomain Acc 73.4 (76.8)\n",
      "Epoch: [0][ 900/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.33 (  1.23)\tCls Acc 71.9 (74.2)\tDomain Acc 68.8 (76.6)\n",
      "Epoch: [0][1000/2500]\tTime  0.04 ( 0.05)\tData  0.04 ( 0.04)\tLoss   0.90 (  1.21)\tCls Acc 93.8 (75.2)\tDomain Acc 67.2 (76.3)\n",
      "Epoch: [0][1100/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.01 (  1.19)\tCls Acc 87.5 (76.0)\tDomain Acc 71.9 (76.1)\n",
      "Epoch: [0][1200/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.10 (  1.17)\tCls Acc 78.1 (76.7)\tDomain Acc 71.9 (75.8)\n",
      "Epoch: [0][1300/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.96 (  1.16)\tCls Acc 78.1 (77.3)\tDomain Acc 75.0 (75.5)\n",
      "Epoch: [0][1400/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.94 (  1.15)\tCls Acc 84.4 (78.0)\tDomain Acc 73.4 (75.1)\n",
      "Epoch: [0][1500/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.00 (  1.14)\tCls Acc 78.1 (78.6)\tDomain Acc 73.4 (74.8)\n",
      "Epoch: [0][1600/2500]\tTime  0.05 ( 0.05)\tData  0.04 ( 0.04)\tLoss   1.05 (  1.13)\tCls Acc 87.5 (79.1)\tDomain Acc 64.1 (74.5)\n",
      "Epoch: [0][1700/2500]\tTime  0.04 ( 0.05)\tData  0.04 ( 0.04)\tLoss   1.15 (  1.12)\tCls Acc 81.2 (79.5)\tDomain Acc 68.8 (74.2)\n",
      "Epoch: [0][1800/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.84 (  1.11)\tCls Acc 90.6 (79.9)\tDomain Acc 71.9 (73.8)\n",
      "Epoch: [0][1900/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.90 (  1.11)\tCls Acc 84.4 (80.2)\tDomain Acc 71.9 (73.5)\n",
      "Epoch: [0][2000/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.00 (  1.10)\tCls Acc 90.6 (80.6)\tDomain Acc 64.1 (73.2)\n",
      "Epoch: [0][2100/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.99 (  1.10)\tCls Acc 90.6 (81.0)\tDomain Acc 59.4 (72.9)\n",
      "Epoch: [0][2200/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.10 (  1.09)\tCls Acc 87.5 (81.3)\tDomain Acc 67.2 (72.6)\n",
      "Epoch: [0][2300/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   1.16 (  1.09)\tCls Acc 84.4 (81.6)\tDomain Acc 60.9 (72.4)\n",
      "Epoch: [0][2400/2500]\tTime  0.04 ( 0.05)\tData  0.03 ( 0.04)\tLoss   0.90 (  1.08)\tCls Acc 90.6 (81.8)\tDomain Acc 65.6 (72.1)\n",
      "Test: [   0/1511]\tTime  0.027 ( 0.027)\tLoss 5.7794e+00 (5.7794e+00)\tAcc@1  21.88 ( 21.88)\n",
      "Test: [ 100/1511]\tTime  0.021 ( 0.020)\tLoss 6.0788e+00 (6.1520e+00)\tAcc@1  18.75 ( 17.64)\n",
      "Test: [ 200/1511]\tTime  0.019 ( 0.020)\tLoss 4.7972e+00 (6.1284e+00)\tAcc@1  25.00 ( 17.97)\n",
      "Test: [ 300/1511]\tTime  0.019 ( 0.020)\tLoss 6.0718e+00 (6.1170e+00)\tAcc@1  18.75 ( 18.58)\n",
      "Test: [ 400/1511]\tTime  0.019 ( 0.020)\tLoss 6.5143e+00 (6.1360e+00)\tAcc@1  18.75 ( 18.51)\n",
      "Test: [ 500/1511]\tTime  0.019 ( 0.020)\tLoss 6.5220e+00 (6.1355e+00)\tAcc@1  18.75 ( 18.48)\n",
      "Test: [ 600/1511]\tTime  0.019 ( 0.020)\tLoss 5.6623e+00 (6.1491e+00)\tAcc@1  28.12 ( 18.38)\n",
      "Test: [ 700/1511]\tTime  0.021 ( 0.020)\tLoss 5.1393e+00 (6.1550e+00)\tAcc@1  28.12 ( 18.35)\n",
      "Test: [ 800/1511]\tTime  0.020 ( 0.020)\tLoss 6.3036e+00 (6.1542e+00)\tAcc@1  18.75 ( 18.37)\n",
      "Test: [ 900/1511]\tTime  0.022 ( 0.020)\tLoss 6.5300e+00 (6.1619e+00)\tAcc@1  15.62 ( 18.46)\n",
      "Test: [1000/1511]\tTime  0.020 ( 0.020)\tLoss 6.9154e+00 (6.1474e+00)\tAcc@1  12.50 ( 18.61)\n",
      "Test: [1100/1511]\tTime  0.019 ( 0.020)\tLoss 6.2115e+00 (6.1435e+00)\tAcc@1  15.62 ( 18.69)\n",
      "Test: [1200/1511]\tTime  0.020 ( 0.020)\tLoss 7.4890e+00 (6.1364e+00)\tAcc@1   3.12 ( 18.73)\n",
      "Test: [1300/1511]\tTime  0.020 ( 0.020)\tLoss 6.4369e+00 (6.1464e+00)\tAcc@1  18.75 ( 18.68)\n",
      "Test: [1400/1511]\tTime  0.020 ( 0.020)\tLoss 6.5621e+00 (6.1460e+00)\tAcc@1  25.00 ( 18.74)\n",
      "Test: [1500/1511]\tTime  0.019 ( 0.020)\tLoss 5.7473e+00 (6.1458e+00)\tAcc@1  15.62 ( 18.77)\n",
      " * Acc@1 18.750\n",
      "global correct: 18.8\n",
      "mean correct:nan\n",
      "mean IoU: 1.9\n",
      "+-----------+-------------------+-------------------+\n",
      "|   class   |        acc        |        iou        |\n",
      "+-----------+-------------------+-------------------+\n",
      "|  0 - zero | 18.75038719177246 | 18.75038719177246 |\n",
      "|  1 - one  |        nan        |        0.0        |\n",
      "|  2 - two  |        nan        |        0.0        |\n",
      "| 3 - three |        nan        |        0.0        |\n",
      "|  4 - four |        nan        |        0.0        |\n",
      "|  5 - five |        nan        |        0.0        |\n",
      "|  6 - six  |        nan        |        0.0        |\n",
      "| 7 - seven |        nan        |        0.0        |\n",
      "| 8 - eight |        nan        |        0.0        |\n",
      "|  9 - nine |        nan        |        0.0        |\n",
      "+-----------+-------------------+-------------------+\n",
      "lr: 0.0003907949713906802\n",
      "Epoch: [1][   0/2500]\tTime  0.04 ( 0.04)\tData  0.04 ( 0.04)\tLoss   0.87 (  0.87)\tCls Acc 96.9 (96.9)\tDomain Acc 65.6 (65.6)\n",
      "Epoch: [1][ 100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.73 (  0.97)\tCls Acc 96.9 (88.8)\tDomain Acc 62.5 (65.8)\n",
      "Epoch: [1][ 200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.88 (  0.96)\tCls Acc 90.6 (89.1)\tDomain Acc 62.5 (65.6)\n",
      "Epoch: [1][ 300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.03 (  0.98)\tCls Acc 90.6 (88.8)\tDomain Acc 67.2 (65.9)\n",
      "Epoch: [1][ 400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.00 (  0.97)\tCls Acc 87.5 (88.7)\tDomain Acc 68.8 (65.7)\n",
      "Epoch: [1][ 500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.12 (  0.97)\tCls Acc 87.5 (88.7)\tDomain Acc 65.6 (65.5)\n",
      "Epoch: [1][ 600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.06 (  0.97)\tCls Acc 87.5 (88.8)\tDomain Acc 65.6 (65.6)\n",
      "Epoch: [1][ 700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.82 (  0.97)\tCls Acc 96.9 (88.9)\tDomain Acc 62.5 (65.3)\n",
      "Epoch: [1][ 800/2500]\tTime  0.05 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.92 (  0.97)\tCls Acc 90.6 (89.0)\tDomain Acc 62.5 (65.4)\n",
      "Epoch: [1][ 900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.73 (  0.96)\tCls Acc 96.9 (89.1)\tDomain Acc 68.8 (65.3)\n",
      "Epoch: [1][1000/2500]\tTime  0.05 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.90 (  0.96)\tCls Acc 90.6 (89.3)\tDomain Acc 54.7 (65.3)\n",
      "Epoch: [1][1100/2500]\tTime  0.05 ( 0.04)\tData  0.04 ( 0.03)\tLoss   1.23 (  0.96)\tCls Acc 87.5 (89.2)\tDomain Acc 65.6 (65.1)\n",
      "Epoch: [1][1200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.83 (  0.96)\tCls Acc 90.6 (89.2)\tDomain Acc 73.4 (65.0)\n",
      "Epoch: [1][1300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.88 (  0.96)\tCls Acc 93.8 (89.4)\tDomain Acc 62.5 (65.0)\n",
      "Epoch: [1][1400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.80 (  0.96)\tCls Acc 96.9 (89.5)\tDomain Acc 70.3 (64.9)\n",
      "Epoch: [1][1500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.80 (  0.96)\tCls Acc 96.9 (89.5)\tDomain Acc 76.6 (64.9)\n",
      "Epoch: [1][1600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.18 (  0.96)\tCls Acc 84.4 (89.6)\tDomain Acc 70.3 (64.8)\n",
      "Epoch: [1][1700/2500]\tTime  0.05 ( 0.04)\tData  0.04 ( 0.03)\tLoss   0.84 (  0.96)\tCls Acc 90.6 (89.6)\tDomain Acc 67.2 (64.6)\n",
      "Epoch: [1][1800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.93 (  0.96)\tCls Acc 90.6 (89.6)\tDomain Acc 65.6 (64.5)\n",
      "Epoch: [1][1900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.01 (  0.96)\tCls Acc 93.8 (89.7)\tDomain Acc 59.4 (64.5)\n",
      "Epoch: [1][2000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.91 (  0.96)\tCls Acc 90.6 (89.7)\tDomain Acc 56.2 (64.4)\n",
      "Epoch: [1][2100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.99 (  0.95)\tCls Acc 90.6 (89.8)\tDomain Acc 67.2 (64.4)\n",
      "Epoch: [1][2200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.78 (  0.95)\tCls Acc 93.8 (89.8)\tDomain Acc 71.9 (64.4)\n",
      "Epoch: [1][2300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.00 (  0.95)\tCls Acc 87.5 (89.9)\tDomain Acc 62.5 (64.3)\n",
      "Epoch: [1][2400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.64 (  0.95)\tCls Acc 100.0 (89.9)\tDomain Acc 71.9 (64.3)\n",
      "Test: [   0/1511]\tTime  0.017 ( 0.017)\tLoss 6.6098e+00 (6.6098e+00)\tAcc@1  15.62 ( 15.62)\n",
      "Test: [ 100/1511]\tTime  0.016 ( 0.016)\tLoss 7.0096e+00 (6.8034e+00)\tAcc@1  15.62 ( 14.33)\n",
      "Test: [ 200/1511]\tTime  0.016 ( 0.016)\tLoss 5.4774e+00 (6.7548e+00)\tAcc@1  25.00 ( 14.60)\n",
      "Test: [ 300/1511]\tTime  0.015 ( 0.016)\tLoss 6.5197e+00 (6.7185e+00)\tAcc@1  12.50 ( 15.18)\n",
      "Test: [ 400/1511]\tTime  0.015 ( 0.016)\tLoss 6.9339e+00 (6.7429e+00)\tAcc@1  18.75 ( 15.23)\n",
      "Test: [ 500/1511]\tTime  0.017 ( 0.016)\tLoss 6.9152e+00 (6.7422e+00)\tAcc@1  12.50 ( 15.23)\n",
      "Test: [ 600/1511]\tTime  0.016 ( 0.016)\tLoss 6.2802e+00 (6.7586e+00)\tAcc@1  21.88 ( 15.18)\n",
      "Test: [ 700/1511]\tTime  0.016 ( 0.016)\tLoss 5.9849e+00 (6.7708e+00)\tAcc@1  21.88 ( 15.17)\n",
      "Test: [ 800/1511]\tTime  0.016 ( 0.016)\tLoss 6.7125e+00 (6.7701e+00)\tAcc@1  18.75 ( 15.17)\n",
      "Test: [ 900/1511]\tTime  0.016 ( 0.016)\tLoss 6.9015e+00 (6.7748e+00)\tAcc@1  15.62 ( 15.22)\n",
      "Test: [1000/1511]\tTime  0.018 ( 0.016)\tLoss 7.3850e+00 (6.7580e+00)\tAcc@1  12.50 ( 15.37)\n",
      "Test: [1100/1511]\tTime  0.015 ( 0.016)\tLoss 6.8671e+00 (6.7546e+00)\tAcc@1  12.50 ( 15.44)\n",
      "Test: [1200/1511]\tTime  0.016 ( 0.016)\tLoss 8.3097e+00 (6.7493e+00)\tAcc@1   3.12 ( 15.46)\n",
      "Test: [1300/1511]\tTime  0.016 ( 0.016)\tLoss 6.4319e+00 (6.7551e+00)\tAcc@1  18.75 ( 15.42)\n",
      "Test: [1400/1511]\tTime  0.015 ( 0.016)\tLoss 6.8130e+00 (6.7533e+00)\tAcc@1  18.75 ( 15.48)\n",
      "Test: [1500/1511]\tTime  0.017 ( 0.016)\tLoss 6.7446e+00 (6.7526e+00)\tAcc@1   9.38 ( 15.51)\n",
      " * Acc@1 15.494\n",
      "global correct: 15.5\n",
      "mean correct:nan\n",
      "mean IoU: 1.5\n",
      "+-----------+--------------------+--------------------+\n",
      "|   class   |        acc         |        iou         |\n",
      "+-----------+--------------------+--------------------+\n",
      "|  0 - zero | 15.493948936462402 | 15.493948936462402 |\n",
      "|  1 - one  |        nan         |        0.0         |\n",
      "|  2 - two  |        nan         |        0.0         |\n",
      "| 3 - three |        nan         |        0.0         |\n",
      "|  4 - four |        nan         |        0.0         |\n",
      "|  5 - five |        nan         |        0.0         |\n",
      "|  6 - six  |        nan         |        0.0         |\n",
      "| 7 - seven |        nan         |        0.0         |\n",
      "| 8 - eight |        nan         |        0.0         |\n",
      "|  9 - nine |        nan         |        0.0         |\n",
      "+-----------+--------------------+--------------------+\n",
      "lr: 0.00026084743001221456\n",
      "Epoch: [2][   0/2500]\tTime  0.05 ( 0.05)\tData  0.04 ( 0.04)\tLoss   0.86 (  0.86)\tCls Acc 90.6 (90.6)\tDomain Acc 75.0 (75.0)\n",
      "Epoch: [2][ 100/2500]\tTime  0.05 ( 0.04)\tData  0.04 ( 0.03)\tLoss   0.86 (  0.92)\tCls Acc 96.9 (90.7)\tDomain Acc 67.2 (64.3)\n",
      "Epoch: [2][ 200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.72 (  0.94)\tCls Acc 96.9 (90.7)\tDomain Acc 71.9 (64.0)\n",
      "Epoch: [2][ 300/2500]\tTime  0.05 ( 0.04)\tData  0.04 ( 0.03)\tLoss   1.15 (  0.92)\tCls Acc 87.5 (91.1)\tDomain Acc 64.1 (64.0)\n",
      "Epoch: [2][ 400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.87 (  0.92)\tCls Acc 96.9 (91.3)\tDomain Acc 70.3 (63.6)\n",
      "Epoch: [2][ 500/2500]\tTime  0.05 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.91 (  0.92)\tCls Acc 93.8 (91.3)\tDomain Acc 73.4 (63.6)\n",
      "Epoch: [2][ 600/2500]\tTime  0.04 ( 0.04)\tData  0.04 ( 0.03)\tLoss   0.84 (  0.91)\tCls Acc 96.9 (91.4)\tDomain Acc 67.2 (63.7)\n",
      "Epoch: [2][ 700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.87 (  0.91)\tCls Acc 90.6 (91.4)\tDomain Acc 62.5 (63.7)\n",
      "Epoch: [2][ 800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.99 (  0.91)\tCls Acc 93.8 (91.5)\tDomain Acc 56.2 (63.5)\n",
      "Epoch: [2][ 900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.91 (  0.91)\tCls Acc 93.8 (91.6)\tDomain Acc 60.9 (63.6)\n",
      "Epoch: [2][1000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.75 (  0.91)\tCls Acc 96.9 (91.6)\tDomain Acc 59.4 (63.6)\n",
      "Epoch: [2][1100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.74 (  0.91)\tCls Acc 96.9 (91.7)\tDomain Acc 60.9 (63.6)\n",
      "Epoch: [2][1200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.06 (  0.91)\tCls Acc 90.6 (91.6)\tDomain Acc 64.1 (63.6)\n",
      "Epoch: [2][1300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.81 (  0.91)\tCls Acc 93.8 (91.7)\tDomain Acc 65.6 (63.5)\n",
      "Epoch: [2][1400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.89 (  0.91)\tCls Acc 96.9 (91.6)\tDomain Acc 59.4 (63.5)\n",
      "Epoch: [2][1500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.88 (  0.91)\tCls Acc 90.6 (91.7)\tDomain Acc 65.6 (63.4)\n",
      "Epoch: [2][1600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.81 (  0.91)\tCls Acc 93.8 (91.7)\tDomain Acc 62.5 (63.4)\n",
      "Epoch: [2][1700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.91 (  0.91)\tCls Acc 87.5 (91.7)\tDomain Acc 56.2 (63.4)\n",
      "Epoch: [2][1800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.05 (  0.91)\tCls Acc 84.4 (91.7)\tDomain Acc 59.4 (63.3)\n",
      "Epoch: [2][1900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.15 (  0.91)\tCls Acc 84.4 (91.7)\tDomain Acc 65.6 (63.3)\n",
      "Epoch: [2][2000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.75 (  0.91)\tCls Acc 96.9 (91.7)\tDomain Acc 68.8 (63.2)\n",
      "Epoch: [2][2100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.17 (  0.91)\tCls Acc 84.4 (91.7)\tDomain Acc 60.9 (63.2)\n",
      "Epoch: [2][2200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.85 (  0.91)\tCls Acc 93.8 (91.7)\tDomain Acc 59.4 (63.2)\n",
      "Epoch: [2][2300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.84 (  0.91)\tCls Acc 93.8 (91.7)\tDomain Acc 57.8 (63.1)\n",
      "Epoch: [2][2400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.91)\tCls Acc 93.8 (91.7)\tDomain Acc 64.1 (63.2)\n",
      "Test: [   0/1511]\tTime  0.016 ( 0.016)\tLoss 7.2244e+00 (7.2244e+00)\tAcc@1  12.50 ( 12.50)\n",
      "Test: [ 100/1511]\tTime  0.018 ( 0.016)\tLoss 7.4238e+00 (7.2605e+00)\tAcc@1  15.62 ( 14.51)\n",
      "Test: [ 200/1511]\tTime  0.015 ( 0.016)\tLoss 6.0204e+00 (7.2182e+00)\tAcc@1  25.00 ( 14.57)\n",
      "Test: [ 300/1511]\tTime  0.016 ( 0.016)\tLoss 6.9738e+00 (7.1860e+00)\tAcc@1  12.50 ( 15.05)\n",
      "Test: [ 400/1511]\tTime  0.016 ( 0.016)\tLoss 7.6221e+00 (7.2137e+00)\tAcc@1  18.75 ( 15.01)\n",
      "Test: [ 500/1511]\tTime  0.016 ( 0.016)\tLoss 7.3806e+00 (7.2105e+00)\tAcc@1  12.50 ( 15.03)\n",
      "Test: [ 600/1511]\tTime  0.019 ( 0.016)\tLoss 6.7825e+00 (7.2297e+00)\tAcc@1  21.88 ( 14.94)\n",
      "Test: [ 700/1511]\tTime  0.015 ( 0.016)\tLoss 6.4350e+00 (7.2434e+00)\tAcc@1  18.75 ( 14.97)\n",
      "Test: [ 800/1511]\tTime  0.015 ( 0.016)\tLoss 7.0938e+00 (7.2411e+00)\tAcc@1  15.62 ( 14.95)\n",
      "Test: [ 900/1511]\tTime  0.016 ( 0.016)\tLoss 7.2969e+00 (7.2446e+00)\tAcc@1  15.62 ( 15.03)\n",
      "Test: [1000/1511]\tTime  0.016 ( 0.016)\tLoss 7.8037e+00 (7.2264e+00)\tAcc@1  12.50 ( 15.20)\n",
      "Test: [1100/1511]\tTime  0.017 ( 0.016)\tLoss 7.2911e+00 (7.2223e+00)\tAcc@1  12.50 ( 15.25)\n",
      "Test: [1200/1511]\tTime  0.015 ( 0.016)\tLoss 8.7801e+00 (7.2169e+00)\tAcc@1   3.12 ( 15.28)\n",
      "Test: [1300/1511]\tTime  0.017 ( 0.016)\tLoss 6.8589e+00 (7.2222e+00)\tAcc@1  18.75 ( 15.23)\n",
      "Test: [1400/1511]\tTime  0.016 ( 0.016)\tLoss 7.2918e+00 (7.2196e+00)\tAcc@1  18.75 ( 15.29)\n",
      "Test: [1500/1511]\tTime  0.016 ( 0.016)\tLoss 7.0397e+00 (7.2189e+00)\tAcc@1   9.38 ( 15.31)\n",
      " * Acc@1 15.302\n",
      "global correct: 15.3\n",
      "mean correct:nan\n",
      "mean IoU: 1.5\n",
      "+-----------+--------------------+--------------------+\n",
      "|   class   |        acc         |        iou         |\n",
      "+-----------+--------------------+--------------------+\n",
      "|  0 - zero | 15.301542282104492 | 15.301542282104492 |\n",
      "|  1 - one  |        nan         |        0.0         |\n",
      "|  2 - two  |        nan         |        0.0         |\n",
      "| 3 - three |        nan         |        0.0         |\n",
      "|  4 - four |        nan         |        0.0         |\n",
      "|  5 - five |        nan         |        0.0         |\n",
      "|  6 - six  |        nan         |        0.0         |\n",
      "| 7 - seven |        nan         |        0.0         |\n",
      "| 8 - eight |        nan         |        0.0         |\n",
      "|  9 - nine |        nan         |        0.0         |\n",
      "+-----------+--------------------+--------------------+\n",
      "lr: 0.00020087958649107584\n",
      "Epoch: [3][   0/2500]\tTime  0.05 ( 0.05)\tData  0.04 ( 0.04)\tLoss   1.03 (  1.03)\tCls Acc 90.6 (90.6)\tDomain Acc 51.6 (51.6)\n",
      "Epoch: [3][ 100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.98 (  0.89)\tCls Acc 87.5 (92.2)\tDomain Acc 67.2 (63.5)\n",
      "Epoch: [3][ 200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.94 (  0.89)\tCls Acc 87.5 (92.6)\tDomain Acc 65.6 (63.3)\n",
      "Epoch: [3][ 300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.75 (  0.90)\tCls Acc 96.9 (92.3)\tDomain Acc 65.6 (63.0)\n",
      "Epoch: [3][ 400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.14 (  0.91)\tCls Acc 90.6 (92.1)\tDomain Acc 46.9 (62.7)\n",
      "Epoch: [3][ 500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.98 (  0.90)\tCls Acc 90.6 (92.2)\tDomain Acc 68.8 (62.7)\n",
      "Epoch: [3][ 600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.89 (  0.90)\tCls Acc 96.9 (92.1)\tDomain Acc 48.4 (62.6)\n",
      "Epoch: [3][ 700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.77 (  0.90)\tCls Acc 96.9 (92.2)\tDomain Acc 67.2 (62.6)\n",
      "Epoch: [3][ 800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.90)\tCls Acc 96.9 (92.2)\tDomain Acc 59.4 (62.7)\n",
      "Epoch: [3][ 900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.92 (  0.90)\tCls Acc 93.8 (92.1)\tDomain Acc 62.5 (62.6)\n",
      "Epoch: [3][1000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.89 (  0.90)\tCls Acc 90.6 (92.1)\tDomain Acc 62.5 (62.7)\n",
      "Epoch: [3][1100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.84 (  0.90)\tCls Acc 93.8 (92.3)\tDomain Acc 59.4 (62.7)\n",
      "Epoch: [3][1200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.76 (  0.89)\tCls Acc 93.8 (92.3)\tDomain Acc 60.9 (62.6)\n",
      "Epoch: [3][1300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.05 (  0.89)\tCls Acc 90.6 (92.3)\tDomain Acc 50.0 (62.6)\n",
      "Epoch: [3][1400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.05 (  0.89)\tCls Acc 87.5 (92.4)\tDomain Acc 56.2 (62.5)\n",
      "Epoch: [3][1500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.76 (  0.89)\tCls Acc 93.8 (92.5)\tDomain Acc 62.5 (62.5)\n",
      "Epoch: [3][1600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.94 (  0.89)\tCls Acc 87.5 (92.5)\tDomain Acc 64.1 (62.5)\n",
      "Epoch: [3][1700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.80 (  0.89)\tCls Acc 96.9 (92.5)\tDomain Acc 65.6 (62.6)\n",
      "Epoch: [3][1800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.73 (  0.89)\tCls Acc 96.9 (92.5)\tDomain Acc 68.8 (62.5)\n",
      "Epoch: [3][1900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.84 (  0.89)\tCls Acc 90.6 (92.5)\tDomain Acc 60.9 (62.5)\n",
      "Epoch: [3][2000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.78 (  0.89)\tCls Acc 96.9 (92.6)\tDomain Acc 64.1 (62.5)\n",
      "Epoch: [3][2100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.69 (  0.89)\tCls Acc 100.0 (92.6)\tDomain Acc 59.4 (62.5)\n",
      "Epoch: [3][2200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.89)\tCls Acc 96.9 (92.6)\tDomain Acc 71.9 (62.4)\n",
      "Epoch: [3][2300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.89 (  0.89)\tCls Acc 93.8 (92.6)\tDomain Acc 60.9 (62.4)\n",
      "Epoch: [3][2400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.71 (  0.89)\tCls Acc 96.9 (92.6)\tDomain Acc 68.8 (62.4)\n",
      "Test: [   0/1511]\tTime  0.017 ( 0.017)\tLoss 7.3418e+00 (7.3418e+00)\tAcc@1  12.50 ( 12.50)\n",
      "Test: [ 100/1511]\tTime  0.016 ( 0.016)\tLoss 7.5913e+00 (7.2767e+00)\tAcc@1  15.62 ( 13.34)\n",
      "Test: [ 200/1511]\tTime  0.015 ( 0.016)\tLoss 5.8800e+00 (7.2219e+00)\tAcc@1  25.00 ( 13.60)\n",
      "Test: [ 300/1511]\tTime  0.016 ( 0.016)\tLoss 6.9380e+00 (7.1787e+00)\tAcc@1  12.50 ( 14.14)\n",
      "Test: [ 400/1511]\tTime  0.015 ( 0.016)\tLoss 7.5968e+00 (7.2094e+00)\tAcc@1  18.75 ( 14.14)\n",
      "Test: [ 500/1511]\tTime  0.016 ( 0.016)\tLoss 7.4099e+00 (7.2058e+00)\tAcc@1  12.50 ( 14.04)\n",
      "Test: [ 600/1511]\tTime  0.016 ( 0.016)\tLoss 6.9850e+00 (7.2249e+00)\tAcc@1  21.88 ( 14.05)\n",
      "Test: [ 700/1511]\tTime  0.016 ( 0.016)\tLoss 6.5462e+00 (7.2392e+00)\tAcc@1  18.75 ( 14.04)\n",
      "Test: [ 800/1511]\tTime  0.016 ( 0.016)\tLoss 7.1884e+00 (7.2362e+00)\tAcc@1  15.62 ( 14.05)\n",
      "Test: [ 900/1511]\tTime  0.016 ( 0.016)\tLoss 7.4258e+00 (7.2384e+00)\tAcc@1  12.50 ( 14.13)\n",
      "Test: [1000/1511]\tTime  0.015 ( 0.016)\tLoss 7.7694e+00 (7.2208e+00)\tAcc@1   9.38 ( 14.28)\n",
      "Test: [1100/1511]\tTime  0.017 ( 0.016)\tLoss 7.0674e+00 (7.2156e+00)\tAcc@1  12.50 ( 14.35)\n",
      "Test: [1200/1511]\tTime  0.019 ( 0.016)\tLoss 8.7913e+00 (7.2108e+00)\tAcc@1   3.12 ( 14.38)\n",
      "Test: [1300/1511]\tTime  0.016 ( 0.016)\tLoss 6.5827e+00 (7.2161e+00)\tAcc@1  18.75 ( 14.32)\n",
      "Test: [1400/1511]\tTime  0.016 ( 0.016)\tLoss 7.0586e+00 (7.2137e+00)\tAcc@1  18.75 ( 14.38)\n",
      "Test: [1500/1511]\tTime  0.016 ( 0.016)\tLoss 7.3605e+00 (7.2140e+00)\tAcc@1   9.38 ( 14.39)\n",
      " * Acc@1 14.393\n",
      "global correct: 14.4\n",
      "mean correct:nan\n",
      "mean IoU: 1.4\n",
      "+-----------+-------------------+-------------------+\n",
      "|   class   |        acc        |        iou        |\n",
      "+-----------+-------------------+-------------------+\n",
      "|  0 - zero | 14.39329719543457 | 14.39329719543457 |\n",
      "|  1 - one  |        nan        |        0.0        |\n",
      "|  2 - two  |        nan        |        0.0        |\n",
      "| 3 - three |        nan        |        0.0        |\n",
      "|  4 - four |        nan        |        0.0        |\n",
      "|  5 - five |        nan        |        0.0        |\n",
      "|  6 - six  |        nan        |        0.0        |\n",
      "| 7 - seven |        nan        |        0.0        |\n",
      "| 8 - eight |        nan        |        0.0        |\n",
      "|  9 - nine |        nan        |        0.0        |\n",
      "+-----------+-------------------+-------------------+\n",
      "lr: 0.0001655600260761702\n",
      "Epoch: [4][   0/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.95 (  0.95)\tCls Acc 90.6 (90.6)\tDomain Acc 59.4 (59.4)\n",
      "Epoch: [4][ 100/2500]\tTime  0.05 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.92 (  0.86)\tCls Acc 90.6 (93.2)\tDomain Acc 60.9 (63.8)\n",
      "Epoch: [4][ 200/2500]\tTime  0.05 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.99 (  0.87)\tCls Acc 90.6 (93.2)\tDomain Acc 64.1 (62.7)\n",
      "Epoch: [4][ 300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.88 (  0.88)\tCls Acc 93.8 (92.8)\tDomain Acc 65.6 (62.4)\n",
      "Epoch: [4][ 400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.88)\tCls Acc 90.6 (92.9)\tDomain Acc 67.2 (62.4)\n",
      "Epoch: [4][ 500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.78 (  0.88)\tCls Acc 96.9 (92.8)\tDomain Acc 60.9 (62.3)\n",
      "Epoch: [4][ 600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.00 (  0.88)\tCls Acc 87.5 (92.7)\tDomain Acc 64.1 (62.2)\n",
      "Epoch: [4][ 700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.75 (  0.88)\tCls Acc 93.8 (92.9)\tDomain Acc 64.1 (62.3)\n",
      "Epoch: [4][ 800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.88)\tCls Acc 96.9 (92.9)\tDomain Acc 53.1 (62.2)\n",
      "Epoch: [4][ 900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.85 (  0.88)\tCls Acc 90.6 (92.9)\tDomain Acc 53.1 (62.2)\n",
      "Epoch: [4][1000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.88)\tCls Acc 96.9 (92.9)\tDomain Acc 54.7 (62.3)\n",
      "Epoch: [4][1100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.79 (  0.88)\tCls Acc 96.9 (92.9)\tDomain Acc 64.1 (62.2)\n",
      "Epoch: [4][1200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.02 (  0.88)\tCls Acc 93.8 (93.0)\tDomain Acc 50.0 (62.2)\n",
      "Epoch: [4][1300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.68 (  0.87)\tCls Acc 96.9 (93.1)\tDomain Acc 68.8 (62.2)\n",
      "Epoch: [4][1400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.96 (  0.87)\tCls Acc 93.8 (93.1)\tDomain Acc 64.1 (62.2)\n",
      "Epoch: [4][1500/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.89 (  0.87)\tCls Acc 93.8 (93.1)\tDomain Acc 64.1 (62.3)\n",
      "Epoch: [4][1600/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.83 (  0.87)\tCls Acc 90.6 (93.1)\tDomain Acc 70.3 (62.3)\n",
      "Epoch: [4][1700/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.83 (  0.87)\tCls Acc 96.9 (93.1)\tDomain Acc 60.9 (62.3)\n",
      "Epoch: [4][1800/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.96 (  0.87)\tCls Acc 93.8 (93.1)\tDomain Acc 46.9 (62.3)\n",
      "Epoch: [4][1900/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.81 (  0.87)\tCls Acc 96.9 (93.1)\tDomain Acc 75.0 (62.3)\n",
      "Epoch: [4][2000/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.80 (  0.87)\tCls Acc 93.8 (93.1)\tDomain Acc 70.3 (62.3)\n",
      "Epoch: [4][2100/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.00 (  0.87)\tCls Acc 87.5 (93.1)\tDomain Acc 65.6 (62.3)\n",
      "Epoch: [4][2200/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   1.05 (  0.87)\tCls Acc 90.6 (93.1)\tDomain Acc 76.6 (62.3)\n",
      "Epoch: [4][2300/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.77 (  0.87)\tCls Acc 93.8 (93.1)\tDomain Acc 60.9 (62.2)\n",
      "Epoch: [4][2400/2500]\tTime  0.04 ( 0.04)\tData  0.03 ( 0.03)\tLoss   0.70 (  0.87)\tCls Acc 93.8 (93.1)\tDomain Acc 73.4 (62.2)\n",
      "Test: [   0/1511]\tTime  0.017 ( 0.017)\tLoss 7.8670e+00 (7.8670e+00)\tAcc@1   9.38 (  9.38)\n",
      "Test: [ 100/1511]\tTime  0.017 ( 0.016)\tLoss 8.1438e+00 (7.6075e+00)\tAcc@1  12.50 ( 12.31)\n",
      "Test: [ 200/1511]\tTime  0.015 ( 0.016)\tLoss 6.2797e+00 (7.5564e+00)\tAcc@1  25.00 ( 12.73)\n",
      "Test: [ 300/1511]\tTime  0.015 ( 0.016)\tLoss 7.2242e+00 (7.5146e+00)\tAcc@1  12.50 ( 13.44)\n",
      "Test: [ 400/1511]\tTime  0.017 ( 0.016)\tLoss 7.8986e+00 (7.5408e+00)\tAcc@1  18.75 ( 13.47)\n",
      "Test: [ 500/1511]\tTime  0.015 ( 0.016)\tLoss 7.7198e+00 (7.5369e+00)\tAcc@1  12.50 ( 13.43)\n",
      "Test: [ 600/1511]\tTime  0.016 ( 0.016)\tLoss 7.0899e+00 (7.5537e+00)\tAcc@1  21.88 ( 13.42)\n",
      "Test: [ 700/1511]\tTime  0.016 ( 0.016)\tLoss 7.0023e+00 (7.5678e+00)\tAcc@1  18.75 ( 13.34)\n",
      "Test: [ 800/1511]\tTime  0.017 ( 0.016)\tLoss 7.4007e+00 (7.5635e+00)\tAcc@1  15.62 ( 13.35)\n",
      "Test: [ 900/1511]\tTime  0.015 ( 0.016)\tLoss 7.4363e+00 (7.5662e+00)\tAcc@1  12.50 ( 13.38)\n",
      "Test: [1000/1511]\tTime  0.017 ( 0.016)\tLoss 7.9105e+00 (7.5495e+00)\tAcc@1   9.38 ( 13.48)\n",
      "Test: [1100/1511]\tTime  0.015 ( 0.016)\tLoss 7.5605e+00 (7.5434e+00)\tAcc@1  12.50 ( 13.55)\n",
      "Test: [1200/1511]\tTime  0.017 ( 0.016)\tLoss 9.0500e+00 (7.5374e+00)\tAcc@1   3.12 ( 13.60)\n",
      "Test: [1300/1511]\tTime  0.016 ( 0.016)\tLoss 6.8917e+00 (7.5431e+00)\tAcc@1  18.75 ( 13.54)\n",
      "Test: [1400/1511]\tTime  0.016 ( 0.016)\tLoss 7.3284e+00 (7.5408e+00)\tAcc@1  18.75 ( 13.59)\n",
      "Test: [1500/1511]\tTime  0.018 ( 0.016)\tLoss 7.8230e+00 (7.5412e+00)\tAcc@1   9.38 ( 13.61)\n",
      " * Acc@1 13.603\n",
      "global correct: 13.6\n",
      "mean correct:nan\n",
      "mean IoU: 1.4\n",
      "+-----------+-------------------+-------------------+\n",
      "|   class   |        acc        |        iou        |\n",
      "+-----------+-------------------+-------------------+\n",
      "|  0 - zero | 13.60297966003418 | 13.60297966003418 |\n",
      "|  1 - one  |        nan        |        0.0        |\n",
      "|  2 - two  |        nan        |        0.0        |\n",
      "| 3 - three |        nan        |        0.0        |\n",
      "|  4 - four |        nan        |        0.0        |\n",
      "|  5 - five |        nan        |        0.0        |\n",
      "|  6 - six  |        nan        |        0.0        |\n",
      "| 7 - seven |        nan        |        0.0        |\n",
      "| 8 - eight |        nan        |        0.0        |\n",
      "|  9 - nine |        nan        |        0.0        |\n",
      "+-----------+-------------------+-------------------+\n",
      "best_acc1 = 18.8\n",
      "Test: [   0/1511]\tTime  0.020 ( 0.020)\tLoss 6.5338e+00 (6.5338e+00)\tAcc@1  12.50 ( 12.50)\n",
      "Test: [ 100/1511]\tTime  0.019 ( 0.020)\tLoss 6.5900e+00 (6.1968e+00)\tAcc@1  18.75 ( 18.72)\n",
      "Test: [ 200/1511]\tTime  0.020 ( 0.020)\tLoss 5.7762e+00 (6.1452e+00)\tAcc@1  21.88 ( 18.95)\n",
      "Test: [ 300/1511]\tTime  0.019 ( 0.020)\tLoss 5.6586e+00 (6.1342e+00)\tAcc@1  25.00 ( 18.98)\n",
      "Test: [ 400/1511]\tTime  0.020 ( 0.020)\tLoss 5.7845e+00 (6.1258e+00)\tAcc@1  25.00 ( 19.01)\n",
      "Test: [ 500/1511]\tTime  0.019 ( 0.020)\tLoss 6.5367e+00 (6.1408e+00)\tAcc@1  15.62 ( 19.05)\n",
      "Test: [ 600/1511]\tTime  0.020 ( 0.020)\tLoss 6.6022e+00 (6.1342e+00)\tAcc@1  15.62 ( 19.04)\n",
      "Test: [ 700/1511]\tTime  0.020 ( 0.020)\tLoss 7.5500e+00 (6.1521e+00)\tAcc@1  12.50 ( 18.86)\n",
      "Test: [ 800/1511]\tTime  0.021 ( 0.020)\tLoss 6.7976e+00 (6.1639e+00)\tAcc@1  12.50 ( 18.76)\n",
      "Test: [ 900/1511]\tTime  0.021 ( 0.020)\tLoss 4.7235e+00 (6.1686e+00)\tAcc@1  25.00 ( 18.83)\n",
      "Test: [1000/1511]\tTime  0.023 ( 0.020)\tLoss 6.6939e+00 (6.1666e+00)\tAcc@1  18.75 ( 18.83)\n",
      "Test: [1100/1511]\tTime  0.028 ( 0.020)\tLoss 5.7262e+00 (6.1753e+00)\tAcc@1  31.25 ( 18.80)\n",
      "Test: [1200/1511]\tTime  0.021 ( 0.020)\tLoss 5.1247e+00 (6.1771e+00)\tAcc@1  28.12 ( 18.76)\n",
      "Test: [1300/1511]\tTime  0.019 ( 0.020)\tLoss 5.8045e+00 (6.1742e+00)\tAcc@1  28.12 ( 18.78)\n",
      "Test: [1400/1511]\tTime  0.020 ( 0.020)\tLoss 6.3562e+00 (6.1753e+00)\tAcc@1  18.75 ( 18.79)\n",
      "Test: [1500/1511]\tTime  0.019 ( 0.020)\tLoss 5.9006e+00 (6.1776e+00)\tAcc@1  28.12 ( 18.79)\n",
      " * Acc@1 18.763\n",
      "global correct: 18.8\n",
      "mean correct:nan\n",
      "mean IoU: 1.9\n",
      "+-----------+--------------------+--------------------+\n",
      "|   class   |        acc         |        iou         |\n",
      "+-----------+--------------------+--------------------+\n",
      "|  0 - zero | 18.762802124023438 | 18.762802124023438 |\n",
      "|  1 - one  |        nan         |        0.0         |\n",
      "|  2 - two  |        nan         |        0.0         |\n",
      "| 3 - three |        nan         |        0.0         |\n",
      "|  4 - four |        nan         |        0.0         |\n",
      "|  5 - five |        nan         |        0.0         |\n",
      "|  6 - six  |        nan         |        0.0         |\n",
      "| 7 - seven |        nan         |        0.0         |\n",
      "| 8 - eight |        nan         |        0.0         |\n",
      "|  9 - nine |        nan         |        0.0         |\n",
      "+-----------+--------------------+--------------------+\n",
      "test_acc1 = 18.8\n",
      "100%|##########| 1875/1875 [00:33<00:00, 55.30it/s]\n",
      "100%|##########| 5610/5610 [01:38<00:00, 57.06it/s]\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "D:\\Programs\\Anaconda3\\envs\\medgc-tesis\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "Saving t-SNE to dann\\visualize\\TSNE.pdf\n",
      "epoch 0 accuracy: 93.68528747558594 A-dist: 1.7474114894866943\n",
      "epoch 1 accuracy: 94.2906723022461 A-dist: 1.7716267108917236\n",
      "epoch 2 accuracy: 94.69564819335938 A-dist: 1.7878258228302002\n",
      "epoch 3 accuracy: 94.75827026367188 A-dist: 1.7903306484222412\n",
      "epoch 4 accuracy: 94.68938446044922 A-dist: 1.7875752449035645\n",
      "epoch 5 accuracy: 93.67903137207031 A-dist: 1.7471611499786377\n",
      "epoch 6 accuracy: 94.90230560302734 A-dist: 1.7960920333862305\n",
      "epoch 7 accuracy: 94.62884521484375 A-dist: 1.7851536273956299\n",
      "epoch 8 accuracy: 94.9670181274414 A-dist: 1.7986805438995361\n",
      "epoch 9 accuracy: 94.96284484863281 A-dist: 1.798513650894165\n",
      "A-distance = tensor(1.7985, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_source_dataset, train_target_dataset, val_dataset, test_dataset, num_classes, args.class_names = \\\n",
    "        get_dataset(args.data, args.root, train_transform, val_transform)\n",
    "\n",
    "train_source_loader = DataLoader(train_source_dataset, batch_size=args.batch_size,\n",
    "                                 shuffle=True, num_workers=args.workers, drop_last=True)\n",
    "train_target_loader = DataLoader(train_target_dataset, batch_size=args.batch_size,\n",
    "                                 shuffle=True, num_workers=args.workers, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers)\n",
    "\n",
    "train_source_iter = ForeverDataIterator(train_source_loader)\n",
    "train_target_iter = ForeverDataIterator(train_target_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a01932a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backbone = get_model()\n",
    "pool_layer = nn.Identity()\n",
    "\n",
    "classifier = ImageClassifier(backbone, num_classes, bottleneck_dim=args.bottleneck_dim,\n",
    "                             pool_layer=pool_layer, finetune=True).to(device)\n",
    "\n",
    "domain_discri = DomainDiscriminator(in_feature=classifier.features_dim, hidden_size=1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c5deb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and lr scheduler\n",
    "optimizer = SGD(classifier.get_parameters() + domain_discri.get_parameters(),\n",
    "                args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "lr_scheduler = LambdaLR(optimizer, lambda x:  args.lr * (1. + args.lr_gamma * float(x)) ** (-args.lr_decay))\n",
    "\n",
    "# define loss function\n",
    "domain_adv = DomainAdversarialLoss(domain_discri).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fb9ebe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume from the best checkpoint\n",
    "if args.phase != 'train':\n",
    "    checkpoint = torch.load(logger.get_checkpoint_path('best'), map_location='cpu')\n",
    "    classifier.load_state_dict(checkpoint)\n",
    "\n",
    "# analysis the model\n",
    "if args.phase == 'analysis':\n",
    "    # extract features from both domains\n",
    "    feature_extractor = nn.Sequential(classifier.backbone, classifier.pool_layer, classifier.bottleneck).to(device)\n",
    "    source_feature = collect_feature(train_source_loader, feature_extractor, device)\n",
    "    target_feature = collect_feature(train_target_loader, feature_extractor, device)\n",
    "    # plot t-SNE\n",
    "    tSNE_filename = osp.join(logger.visualize_directory, 'TSNE.pdf')\n",
    "    tsne.visualize(source_feature, target_feature, tSNE_filename)\n",
    "    print(\"Saving t-SNE to\", tSNE_filename)\n",
    "    # calculate A-distance, which is a measure for distribution discrepancy\n",
    "    A_distance = a_distance.calculate(source_feature, target_feature, device)\n",
    "    print(\"A-distance =\", A_distance)\n",
    "\n",
    "if args.phase == 'test':\n",
    "    acc1 = validate(test_loader, classifier, args, device)\n",
    "    print(acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c73c9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "best_acc1 = 0.\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"lr:\", lr_scheduler.get_last_lr()[0])\n",
    "    \n",
    "    # train for one epoch\n",
    "    train(train_source_iter, train_target_iter, classifier, domain_adv, optimizer,\n",
    "          lr_scheduler, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, classifier, args, device)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    torch.save(classifier.state_dict(), logger.get_checkpoint_path('latest'))\n",
    "    if acc1 > best_acc1:\n",
    "        shutil.copy(logger.get_checkpoint_path('latest'), logger.get_checkpoint_path('best'))\n",
    "    best_acc1 = max(acc1, best_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7eaa211",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_acc1 = {:3.1f}\".format(best_acc1))\n",
    "\n",
    "# evaluate on test set\n",
    "classifier.load_state_dict(torch.load(logger.get_checkpoint_path('best')))\n",
    "acc1 = validate(test_loader, classifier, args, device)\n",
    "print(\"test_acc1 = {:3.1f}\".format(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2bea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEDGCTesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
